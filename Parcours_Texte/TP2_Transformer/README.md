# TP 2: Transformer

![](https://camo.githubusercontent.com/97702757b4cd91416e4636d1761d5487b8745aa682f81e3036b7f64c2a380342/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f75796974726f612f64726166742d7472616e73666f2d77696b692f6d61696e2f636861746770742e706e67)

## Description
Bienvenue à l'un des TPs les plus longs de ce repo. Aujourd'hui on va s'intéresser à l'architecture des transformers. Un transformer est un réseau de neurones qui permet de transformer des séquences de données en d'autres séquences de données. Il est très utilisé dans le domaine du NLP pour faire de la traduction de texte par exemple. C'est aussi l'architecture derrière le fameux ChatGPT, que vous connaissez déjà.

Les modèles de génération d'images comme DALLE utilisent aussi des transformers, pour encoder le texte.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deeper](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/deeper.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 2012, les chercheurs ont pu montrer l'efficacité des CNN traditionels (couche de convolution suivie d'une fonction d'activation et d'une operation de pooling) pour classifier des images. \n",
    "Vous avez pu constaté la puissance des CNN grâce à nos TPs. Les performances sont nettement améliorées par rapport à des réseaux classiques.\n",
    "\n",
    "\n",
    "Une grande partie du succès des Réseaux de Neurones Profonds a été attribuée à ces couches supplémentaires. L'intuition derrière leur fonction est que ces couches apprennent progressivement des caractéristiques de plus en plus complexes. La première couche apprend les bords, la deuxième couche apprend les formes, la troisième couche apprend les objets, la quatrième couche apprend les yeux, et ainsi de suite. \n",
    "\n",
    "Ainsi la phrase, \"We need to go deeper\" est apparue. L'idée c'était qu'en créant des réseaux de plus en plus profonds en arriverait à apprendre des fonctions de plus en plus complexes. Malheuresement, ça n'a pas marché. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/layers.png\" alt=\"Skip Connection\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un des problèmes que les réseaux trop profonds doivent faire face sont les vanishing/exploding gradients : \n",
    "\n",
    "Le problème du vanishing gradient se produit lors de la backpropagation des gradients lors de l'apprentissage de réseaux de neurones à de nombreuses couches. En effet, lorsque nous utilisons le fonction d'activation de type sigmoid ou tanh, on peut arriver à des situations où les gradients sont beaucoup trop faibles. Puisque les calculs pour la mise à jour des poids se fait à l'aide de la règle de la chaîne, l'apparition d'un 0 sur une des dérivées résulte à des zeros partout. \n",
    "\n",
    "![image.png](https://github.com/Automatants/projets-de-permanence/blob/master/image-hosting/resnet/gradients.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir ici que la dérivée de la sigmoid est très souvent proche de zero.\n",
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/sigmoid.webp\" alt=\"Skip Connection\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 \n",
    "Utilisez des réseaux CNN pour classifier les images de CIFAR10. Essayez de regarder vos performances en fonction de la profondeur, i.e. le nombre des couches de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        ....\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        ........\n",
    "        pass\n",
    "\n",
    "net = Network()\n",
    "optimizer = ...\n",
    "criterion = ...\n",
    "\n",
    "for epoch in range(...):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = ....\n",
    "        loss = ....\n",
    "        ....\n",
    "        .....\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "# Test the network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = ...\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/skip.png\" alt=\"Skip Connection\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image ci-dessus est l'élément le plus important à retenir . Pour les développeurs qui souhaitent le mettre en œuvre rapidement et le tester, la modification la plus importante à comprendre est la \"connexion de saut\" ou la \"mise en correspondance d'identité\". Cette mise en correspondance d'identité n'a pas de paramètres et sert simplement à ajouter la sortie de la couche précédente à la couche suivante. Cependant, parfois, x et F(x) n'auront pas la même dimension. Rappelons qu'une opération de convolution réduit généralement la résolution spatiale d'une image, par exemple, une convolution 3x3 sur une image de 32 x 32 donne une image de 30 x 30. La mise en correspondance d'identité est multipliée par une projection linéaire W pour étendre les canaux du raccourci afin de les faire correspondre au résidu. Cela permet d'associer l'entrée x et F(x) en tant qu'entrée pour la couche suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de tout mettre en application et créer notre ResNet. On va s'inspirer du ResNet 18 mais en plus simple et plus petit pour qu'on puisse entrainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementer ResNet et entrainer le sur CIFAR10\n",
    "\n",
    "#Structure à suivre\n",
    "### Premier bloc\n",
    "# Convolution 3x3, 16, padding 1, stride 1\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "### Deuxième bloc\n",
    "# Convolution 3x3, 16, padding 1, stride 1\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "## Skip connection avec le debut du deuxième bloc\n",
    "### Troisième bloc\n",
    "# Convolution 3x3, 32, padding 1, stride 2\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "## Skip connection avec le début du troisième bloc\n",
    "# MaxPool 2x2\n",
    "# Flatten\n",
    "# Fully connected 32 *8 * 8 -> 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"download.jpg\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux résiduels, ou ResNets en abrégé, sont un type d'architecture de réseau neuronal qui a révolutionné l'apprentissage en profondeur et a eu un impact significatif sur le domaine de la vision par ordinateur.\n",
    "\n",
    "Ils ont été introduits dans l'article intitulé \"Deep Residual Learning for Image Recognition\" (Apprentissage résiduel profond pour la reconnaissance d'images) rédigé par Kaiming He, Xiangyu Zhang, Shaoqing Ren et Jian Sun. \n",
    "\n",
    "\n",
    "L'introduction des ResNets a permis de résoudre le problème de l'entraînement de réseaux neuronaux très profonds, qui était auparavant difficile en raison de problèmes tels que la disparition des gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une grande partie du succès des réseaux neuronaux profonds est attribuée à ces couches supplémentaires. \n",
    "\n",
    "L'intuition derrière leur fonctionnement est que ces couches apprennent progressivement des caractéristiques de plus en plus complexes. La première couche apprend les bords, la deuxième couche apprend les formes, la troisième couche apprend les objets, la quatrième couche apprend les yeux, et ainsi de suite. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 \n",
    "Utilisez des réseaux CNN pour classifier les images de CIFAR10. Essayez de regarder vos performances en fonction de la profondeur, i.e. le nombre des couches de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"skip connection.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image ci-dessus est l'élément le plus important à retenir de cet article. Pour les développeurs qui souhaitent le mettre en œuvre rapidement et le tester, la modification la plus importante à comprendre est la \"connexion de saut\" ou la \"mise en correspondance d'identité\". Cette mise en correspondance d'identité n'a pas de paramètres et sert simplement à ajouter la sortie de la couche précédente à la couche suivante. Cependant, parfois, x et F(x) n'auront pas la même dimension. Rappelons qu'une opération de convolution réduit généralement la résolution spatiale d'une image, par exemple, une convolution 3x3 sur une image de 32 x 32 donne une image de 30 x 30. La mise en correspondance d'identité est multipliée par une projection linéaire W pour étendre les canaux du raccourci afin de les faire correspondre au résidu. Cela permet d'associer l'entrée x et F(x) en tant qu'entrée pour la couche suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 \n",
    " \n",
    "Créer un classe skip connection qui implemente cette opération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##\n",
    "import torch.nn as nn\n",
    "\n",
    "class skip_connection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(skip_connection, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de tout mettre en application et créer notre ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementer ResNet\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

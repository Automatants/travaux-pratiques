{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction aux ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deeper](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/deeper.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 2012, les chercheurs ont pu montrer l'efficacité des CNN traditionnels (couche de convolution suivie d'une fonction d'activation et d'une opération de pooling) pour classifier des images. Vous avez pu constater la puissance des CNN grâce à nos TPs. Les performances sont nettement améliorées par rapport à des réseaux classiques.\n",
    "\n",
    "Une grande partie du succès des Réseaux de Neurones Profonds a été attribuée à ces couches supplémentaires. L'intuition derrière leur fonction est que ces couches apprennent progressivement des caractéristiques de plus en plus complexes. La première couche apprend les bords, la deuxième couche apprend les formes, la troisième couche apprend les objets, la quatrième couche apprend les yeux, et ainsi de suite.\n",
    "\n",
    "Ainsi, la phrase \"We need to go deeper\" est apparue. L'idée était qu'en créant des réseaux de plus en plus profonds, on arriverait à apprendre des fonctions de plus en plus complexes. Malheureusement, cela n'a pas marché. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/layers.png\" alt=\"Skip Connection\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un des problèmes auxquels les réseaux trop profonds doivent faire face est celui des gradients s'éteignant ou explosant :\n",
    "\n",
    "Le problème du vanishing gradient se produit lors de la rétropropagation des gradients pendant l'apprentissage de réseaux de neurones comportant de nombreuses couches. En effet, lorsque nous utilisons des fonctions d'activation de type sigmoïde ou tangente hyperbolique, il peut se produire des situations où les gradients deviennent excessivement faibles. Étant donné que les calculs pour la mise à jour des poids se basent sur la règle de la chaîne, la présence d'un zéro dans l'une des dérivées entraîne des zéros partout\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/gradients.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir ici que la dérivée de la sigmoid est très souvent proche de zero.\n",
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/sigmoid.webp\" alt=\"Skip Connection\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 \n",
    "Utilisez des réseaux CNN pour classifier les images de CIFAR10. Essayez de regarder vos performances en fonction de la profondeur, i.e. le nombre des couches de votre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        ....\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        ........\n",
    "        pass\n",
    "\n",
    "net = Network()\n",
    "optimizer = ...\n",
    "criterion = ...\n",
    "\n",
    "for epoch in range(...):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = ....\n",
    "        loss = ....\n",
    "        ....\n",
    "        .....\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "# Test the network on the test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = ...\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/resnet/skip.png\" alt=\"Skip Connection\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image ci-dessus est l'élément le plus important à retenir, elle correspond à une skip connection.\n",
    "\n",
    "Ainsi, il suffit d'ajouter, sans multiplier par des paramètres, la sortie d'une couche précédente à la couche actuelle. Parfois, x et F(x) n'auront pas la même dimension, vu que les convolutions peuvent changer les dimensions des images. Il y a plusieurs manières de gérer ce décalage :\n",
    "\n",
    " - Padder l'image si les dimensions sont presque les mêmes\n",
    " - Utiliser une convolution appropriée pour ajuster les dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est temps de tout mettre en application et créer notre ResNet. On va s'inspirer du ResNet 18 mais en plus simple et plus petit pour qu'on puisse entrainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementer ResNet et entrainer le sur CIFAR10\n",
    "\n",
    "#Structure à suivre\n",
    "### Premier bloc\n",
    "# Convolution 3x3, 16, padding 1, stride 1\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "### Deuxième bloc\n",
    "# Convolution 3x3, 16, padding 1, stride 1\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "## Skip connection avec le debut du deuxième bloc\n",
    "### Troisième bloc\n",
    "# Convolution 3x3, 32, padding 1, stride 2\n",
    "# BatchNorm\n",
    "# ReLU\n",
    "## Skip connection avec le début du troisième bloc\n",
    "# MaxPool 2x2\n",
    "# Flatten\n",
    "# Fully connected 32 *8 * 8 -> 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge CIFAR \n",
    " \n",
    "Lien : https://sharing.cs-campus.fr/compete/90"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

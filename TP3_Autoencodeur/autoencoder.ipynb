{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Autoencodeur\n",
    "\n",
    "## Introduction aux Autoencodeurs\n",
    "Les autoencodeurs sont des réseaux de neurones qui apprennent à encoder des données en une représentation de dimension réduite, puis à décoder cette représentation pour reconstruire les données originales ou créer des nouvelles données.\n",
    "\n",
    "![Auto encoder](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/TP3_Autoencodeur/autoencoder.png)\n",
    "\n",
    "Les auto-encodeurs sont composés de deux parties principales: l'encodeur et le décodeur.\n",
    "\n",
    "![Encoder Decoder](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/TP3_Autoencodeur/encoderdecoder.png)\n",
    "\n",
    "Encodeur: Cette partie du réseau prend en entrée des données brutes (comme une image) et les comprime en une représentation latente. Cette représentation latente est un ensemble réduit de caractéristiques qui retient l'information essentielle de l'entrée.\n",
    "\n",
    "Décodeur: Le décodeur prend la représentation latente générée par l'encodeur et la décode pour produire une sortie qui se rapproche le plus possible de ce qu'on veut obtenir (par exemple de la segmentation d'image, ou du débruitage d'image).\n",
    "\n",
    "Dans ce TP, on va implémenter un autoencodeur pour faire du débruitage d'image de MNIST.\n",
    "\n",
    "![Denoise](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/TP3_Autoencodeur/denoise.png)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation des données\n",
    "On va télécharger le dataset MNIST puis mettre du bruit sur les images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = train_dataset.data\n",
    "X_test = test_dataset.data\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 1: Normalisation des images et ajout de bruit\n",
    "Normaliser les images en [0, 1] et ajouter du bruit sur les images de train et de test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_normalized = ...\n",
    "X_test_normalized = ...\n",
    "...\n",
    "X_train_noise = ...\n",
    "X_test_noise = ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 2: Visualisation des données bruitées"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 3: Création du modèle\n",
    "Voici le schéma du modèle que l'on va créer:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# Layer (type)               Output Shape\n",
    "# ================================================================\n",
    "# Input              [1, 28, 28]\n",
    "# Conv2d             [16, 28, 28]\n",
    "# MaxPool2d          [16, 14, 14]\n",
    "# Conv2d             [8, 14, 14]\n",
    "# MaxPool2d          [8, 7, 7]\n",
    "# Conv2d             [8, 7, 7]\n",
    "# MaxPool2d          [8, 3, 3]\n",
    "# Conv2d             [8, 3, 3]\n",
    "# ConvTranspose2d    [8, 3, 3]\n",
    "# ConvTranspose2d    [8, 7, 7]\n",
    "# ConvTranspose2d    [8, 14, 14]\n",
    "# ConvTranspose2d    [16, 28, 28]\n",
    "# ConvTranspose2d    [1, 28, 28]\n",
    "# ----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avec des ReLU entre chaque couche."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\t...\n",
    "\n",
    "\tdef forward(self):\n",
    "\t\t..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 4: Entraînement du modèle\n",
    "\n",
    "Pour entraîner le modèle, on met en entrée les images bruitées et on va comparer la sortie du modèle avec les images orignales (donc X_train)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "loss_fn = ...\n",
    "optimizer = ...\n",
    "\n",
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualiser les résultats sur les données de test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Améliorations\n",
    "\n",
    "On peut améliorer le modèle en ajoutant des couches, en changeant les hyperparamètres, en changeant la learning rate, etc...\n",
    "Vous pouvez aussi essayer d'accélerer l'entraînement en utilisant le GPU."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Challenge: Denoising Dirty Documents/Remove noise from printed text\n",
    "\n",
    "![Dirty Documents](https://raw.githubusercontent.com/Automatants/projets-de-permanence/master/image-hosting/TP3_Autoencodeur/denoisingdocument.JPG)\n",
    "\n",
    "Lien vers le challenge: https://sharing.cs-campus.fr/compete/89"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
